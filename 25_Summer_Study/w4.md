# 7. ë”¥ëŸ¬ë‹ì„ ì‹œì‘í•©ë‹ˆë‹¤.

## ğŸ“Œ 7.1 ì¸ê³µ ì‹ ê²½ë§

>### fashion mnist data
```python
import matplotlib.pyplot as plt
fig, axs = plt.subplots(1, 10, figsize=(10,10))
for i in range (10):
  axs[i].imshow(train_input[i], cmap = 'gray_r')
  axs[i].axis("off")
plt.show()
```

![]()
* 28 * 28 sizeì˜ ì‚¬ì§„ì´ë¼ ì‘ê³  íë¦¿í•¨. 
* 0~9ê¹Œì§€ì˜ labelì€ ì˜· ì¢…ë¥˜ë¥¼ ì˜ë¯¸

>### ë¡œì§€ìŠ¤í‹± íšŒê·€ë¡œ íŒ¨ì…˜ ì•„ì´í…œ ë¶„ë¥˜í•˜ê¸°
- í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²• í´ë˜ìŠ¤ì˜ loss ë§¤ê°œë³€ìˆ˜ë¥¼ 'log'ë¡œ ì§€ì •í•˜ì—¬ ë¡œì§€ìŠ¤í‹± ì†ì‹¤í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” SGD model ìƒì„± ê°€ëŠ¥  
    * í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•ì€ ì—¬ëŸ¬ íŠ¹ì„±ì¤‘ ê¸°ìš¸ê¸°ê°€ ê°€ì¥ ê°€íŒŒë¥¸ ë°©í–¥ìœ¼ë¡œ ì´ë™í•˜ë¯€ë¡œ ì •ê·œí™”ë¥¼ í•´ì•¼í•œë‹¤.

```python
train_scaled = train_input/255.0
train_Scaled = train_scaled.reshape(-1, 28*28) 
print(train_scaled.shape) # (60000, 784)
```
* reshape() ë©”ì„œë“œì˜ ë‘ë²ˆì§¸ ë§¤ê°œë³€ìˆ˜ë¥¼ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì§€ì •í•˜ë©´ ì²«ë²ˆì¨° ì°¨ì› = ìƒ˜í”Œê¸°ìˆ˜ëŠ” ë³€í•˜ì§€ ì•Šê³  ì›ë³¸ë°ì´í„°ì˜ ë‘, ì„¸ë²ˆì§¸ ì°¨ì›ì´ 1ì°¨ì›ìœ¼ë¡œ í•©ì³ì§ 

```python
from sklearn.model_selection import cross_validate
from sklearn.linear_model import SGDClassifier
sc = SGDClassifier(loss = 'log', max_iter=5, random_state=42)
scores = cross_validate(sc, train_scaled,train_target,n_jobs=-1 )
print(np.mean(scores['test_score']))
```
* 81% ì„±ëŠ¥ì´ ë‚˜ì˜´
> ğŸ“ 784ê°œì˜ í”¼ì³ê°€ ìˆìœ¼ë¯€ë¡œ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ë§Œë“¤ë•Œ ì•„ì£¼ ê¸´ ì‹, ì•„ì£¼ ë§ì€ ê°€ì¤‘ì¹˜...ê·¸ë¦¬ê³  ì˜·ì˜ ì¢…ë¥˜ì— ë”°ë¼ ì´ ê°€ì¤‘ì¹˜ë¥¼ ë‹¤ ê°ê° ê³„ì‚°í•´ì•¼í•¨

>### ì¸ê³µì‹ ê²½ë§
![]()

* êµ¬ì„±ìš”ì†Œ
    1) ì…ë ¥ì¸µ
    2) ê°€ì¤‘ì¹˜
    3) hidden layer
    4) ì¶œë ¥ì¸µ = ë‰´ëŸ°
> ì¸ê³µì‹ ê²½ë§ì€ ê¸°ì¡´ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì´ ì˜ í•´ê²°í•˜ì§€ ëª»í•œ ë¬¸ì œì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ëŠ” ìƒˆë¡œìš´ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ìŒ!

* **tensroflow** ì—ì„œë„ **keras** APIë¥¼ ì‚¬ìš©í•  ì˜ˆì •
    * ì¸ê³µì‹ ê²½ë§ì—ì„œëŠ” êµì°¨ê²€ì¦ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ê²€ì¦ì„¸íŠ¸ë¥¼ ë³„ë„ë¡œ ì‚¬ìš© cuz dataê°€ ì´ë¯¸ ì¶©ë¶„íˆ í¬ê¸° ë•Œë¬¸ì—

```
ğŸ“Œ keras ì„¤ëª…
- ë‹¤ì–‘í•œ ì¸µì´ ìˆê³  ê¸°ë¶„ì€ ë°€ì§‘ì¸µ = dense layer
- ì–‘ìª½ì˜ ë‰´ëŸ°ì´ ëª¨ë‘ ì—°ê²°ë˜ê³  ìˆìœ¼ë©´ FCN(fully connectd layer)
```

```python
dense = keras.layers.Dense(10, activation = 'softmax', input_shape = (784,))
```
* ì²«ë²ˆì§¸ ë§¤ê°œë³€ìˆ˜ = ë‰´ëŸ°ì˜ ê°œìˆ˜ = ì¶œë ¥ì¸µ ê°œìˆ˜
* ì¶œë ¥ë˜ëŠ” ê°’ì„ í™•ë¥ ë¡œ ë°”ê¾¸ê¸° ìœ„í•´ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ ì‚¬ìš©
    *  ì´ì§„ë¶„ë¥˜ë¼ë©´ sigmoidê² ì§€ë§Œ ì†Œí”„íŠ¸ë§¥ìŠ¤ë„ ê°€ëŠ¥
* ì„¸ë²ˆì§¸ ë§¤ê²¨ë³€ìˆ˜ëŠ” ì…ë ¥ì¸µì˜ í¬ê¸°

```python
model = keras.Sequential([dense])
```
* Sequential í´ë˜ìŠ¤ì˜ ê°ì²´ë¥¼ ë§Œë“¤ë•Œ ì•ì„œ ë§Œë“  ë°€ì§‘ì¸µì˜ ê°ì²´ dense ì „ë‹¬í•¨


---
# Sequential vs Dense by Gpt

## âœ… 1. `Dense` ê°ì²´ë€?

### ğŸ”¹ ì—­í• : **ì‹ ê²½ë§ì˜ â€˜ì¸µâ€™(Layer)ì„ ë§Œë“œëŠ” í´ë˜ìŠ¤**

* `Dense`ëŠ” Kerasì—ì„œ **ì™„ì „ ì—°ê²°ì¸µ(Fully Connected Layer, FCN)** ë˜ëŠ” **ë°€ì§‘ì¸µ**ì„ ë§Œë“¤ê¸° ìœ„í•œ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
* ì´ ì¸µì€ **ëª¨ë“  ì…ë ¥ ë‰´ëŸ°ì´ ëª¨ë“  ì¶œë ¥ ë‰´ëŸ°ì— ì—°ê²°**ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

### ğŸ”¹ ì£¼ìš” ë§¤ê°œë³€ìˆ˜

```python
keras.layers.Dense(units, activation, input_shape)
```

| ë§¤ê°œë³€ìˆ˜          | ì˜ë¯¸                                             |
| ------------- | ---------------------------------------------- |
| `units`       | ì¶œë ¥ ë‰´ëŸ°(ë…¸ë“œ)ì˜ ê°œìˆ˜ â†’ ì¦‰, ì´ ì¸µì´ ì¶œë ¥í•˜ëŠ” ë²¡í„°ì˜ í¬ê¸°            |
| `activation`  | í™œì„±í™” í•¨ìˆ˜ (ì˜ˆ: `'relu'`, `'sigmoid'`, `'softmax'`) |
| `input_shape` | ì…ë ¥ ë²¡í„°ì˜ í¬ê¸° (ë§¨ ì•ì¸µì—ì„œë§Œ ì§€ì •í•¨)                        |

### ğŸ”¹ ì˜ˆì‹œ ì„¤ëª…

```python
dense = keras.layers.Dense(10, activation='softmax', input_shape=(784,))
```

* ì…ë ¥: 784ì°¨ì› ë²¡í„° (ì˜ˆ: 28Ã—28 í”½ì…€ ì´ë¯¸ì§€ë¥¼ 1ì°¨ì›ìœ¼ë¡œ í¼ì¹¨)
* ì¶œë ¥: 10ê°œì˜ í™•ë¥ ê°’ (ì˜ˆ: ìˆ«ì ë¶„ë¥˜ ë¬¸ì œì—ì„œ 0\~9ê¹Œì§€ì˜ í™•ë¥ )
* `softmax`: ì¶œë ¥ê°’ì˜ ì´í•©ì´ 1ì´ ë˜ë„ë¡ í•˜ì—¬ ë‹¤ì¤‘ í´ë˜ìŠ¤ í™•ë¥ ë¡œ ë³€í™˜

---

## âœ… 2. `Sequential` ê°ì²´ë€?

### ğŸ”¹ ì—­í• : **ì¸µì„ ì°¨ë¡€ë¡œ ìŒ“ì€ ì¸ê³µì‹ ê²½ë§ ëª¨ë¸ì„ ë§Œë“œëŠ” í´ë˜ìŠ¤**

* `Sequential`ì€ kerasì˜ ê°€ì¥ ê¸°ë³¸ì ì¸ ëª¨ë¸ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
* ì—¬ëŸ¬ ì¸µì„ **ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°**í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
* ë‚´ë¶€ì ìœ¼ë¡œëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì¸µì„ ì €ì¥í•¨.

### ğŸ”¹ ì˜ˆì‹œ

```python
model = keras.Sequential([dense])
```

í˜¹ì€ ì´ë ‡ê²Œë„ ê°€ëŠ¥:

```python
model = keras.Sequential([
    keras.layers.Dense(64, activation='relu', input_shape=(784,)),
    keras.layers.Dense(10, activation='softmax')
])
```

### ğŸ”¹ íŠ¹ì§•

* ìœ„ì—ì„œ ì•„ë˜ë¡œ ì¸µì´ ìˆœì°¨ì ìœ¼ë¡œ êµ¬ì„±ë¨
* ê° ì¸µì˜ ì¶œë ¥ì´ ë‹¤ìŒ ì¸µì˜ ì…ë ¥ìœ¼ë¡œ ë°”ë¡œ ì—°ê²°ë¨
* ë³µì¡í•œ êµ¬ì¡°(ì˜ˆ: ì”ì°¨ ì—°ê²°, ë³‘ë ¬ ì—°ê²° ë“±)ëŠ” `Functional API`ë‚˜ `Model` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©

---

## âœ… ì°¨ì´ì  ìš”ì•½: `Dense` vs `Sequential`

| í•­ëª©    | `Dense`                   | `Sequential`                 |
| ----- | ------------------------- | ---------------------------- |
| ì˜ë¯¸    | í•˜ë‚˜ì˜ **ë ˆì´ì–´(ì¸µ)**            | ì—¬ëŸ¬ ì¸µì„ ìŒ“ì•„ì„œ ë§Œë“  **ëª¨ë¸ êµ¬ì¡°**       |
| ì—­í•     | ë‰´ëŸ°ë“¤ì˜ ì§‘í•© (FCN, ì™„ì „ ì—°ê²°ì¸µ) êµ¬ì„±  | ì¸µë“¤ì„ ìˆœì„œëŒ€ë¡œ ì—°ê²°í•´ í•˜ë‚˜ì˜ ì „ì²´ ì‹ ê²½ë§ êµ¬ì„±   |
| ì‚¬ìš© ìœ„ì¹˜ | ëª¨ë¸ ë‚´ë¶€ì—ì„œ ì¸µìœ¼ë¡œ ì‚¬ìš©            | ëª¨ë¸ ìì²´ë¡œ ì‚¬ìš©ë˜ë©°, ì—¬ëŸ¬ ì¸µì„ í¬í•¨        |
| ì˜ˆì‹œ    | `keras.layers.Dense(...)` | `keras.Sequential([...])`    |
| í™•ì¥ì„±   | ë‹¨ì¼ ì¸µë§Œ êµ¬ì„±í•¨                 | ì—¬ëŸ¬ ì¸µì„ í¬í•¨í•  ìˆ˜ ìˆìœ¼ë©°, í•™ìŠµ/í‰ê°€/ì˜ˆì¸¡ ê°€ëŠ¥ |

---

>### ì¸ê³µì‹ ê²½ë§ìœ¼ë¡œ mnist ë¶„ë¥˜í•˜ê¸°


#### âœ… `model.compile()`ì´ë€?

ğŸ”¹ ì—­í• : ëª¨ë¸ì˜ í•™ìŠµ ë°©ë²•ì„ ì§€ì •

* ì†ì‹¤ í•¨ìˆ˜ (`loss`)
* ìµœì í™” ì•Œê³ ë¦¬ì¦˜ (`optimizer`)
* í‰ê°€ ì§€í‘œ (`metrics`)

---

âœ… ê¸°ë³¸ êµ¬ì¡°

```python
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
```

---

âœ… ê° ë§¤ê°œë³€ìˆ˜ ì„¤ëª…

| ë§¤ê°œë³€ìˆ˜        | ì˜ë¯¸                                                                              |
| ----------- | ------------------------------------------------------------------------------- |
| `optimizer` | ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ **ì–´ë–»ê²Œ ê°±ì‹ **í• ì§€ ê²°ì •í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜<br>(ex. `'sgd'`, `'adam'`, `'rmsprop'`, ...)    |
| `loss`      | ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì˜ëª» ì˜ˆì¸¡í–ˆëŠ”ì§€ ê³„ì‚°í•˜ëŠ” **ì†ì‹¤ í•¨ìˆ˜**<br>(ex. `categorical_crossentropy`, `mse`, ...) |
| `metrics`   | í•™ìŠµ ë° í‰ê°€í•  ë•Œ í™•ì¸í•  **ì„±ëŠ¥ ì§€í‘œ**<br>(ë³´í†µ `'accuracy'`, `'mae'` ë“± ì‚¬ìš©)                     |

---

âœ… ì˜ˆì‹œ

ğŸ“Œ ë¶„ë¥˜ ë¬¸ì œ (ë‹¤ì¤‘ í´ë˜ìŠ¤)

```python
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
```

ğŸ“Œ íšŒê·€ ë¬¸ì œ

```python
model.compile(
    optimizer='adam',
    loss='mean_squared_error',   # ë˜ëŠ” 'mse'
    metrics=['mae']              # í‰ê·  ì ˆëŒ€ ì˜¤ì°¨
)
```

ğŸ“Œ ì´ì§„ ë¶„ë¥˜ ë¬¸ì œ

```python
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)
```

---

âœ… í•„ìš”ì„±

`compile()`ì„ í•˜ì§€ ì•Šìœ¼ë©´ `fit()`ì´ë‚˜ `evaluate()`ë¥¼ ì“¸ ìˆ˜ ì—†ì–´ìš”.
ì¦‰, **í•™ìŠµì´ ë¶ˆê°€ëŠ¥**

---

#### âœ… ìš”ì•½

| ë‹¨ê³„           | í•¨ìˆ˜                          | ì—­í•                      |
| ------------ | --------------------------- | ---------------------- |
| 1ï¸âƒ£ ëª¨ë¸ êµ¬ì¡° ì •ì˜ | `Sequential()` ë˜ëŠ” `Model()` | ì‹ ê²½ë§ êµ¬ì¡° ë§Œë“¤ê¸°             |
| 2ï¸âƒ£ í•™ìŠµ ì„¤ì •    | `compile()`                 | ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €, í‰ê°€ ì§€í‘œ ì§€ì • |
| 3ï¸âƒ£ í•™ìŠµ ì‹œì‘    | `fit()`                     | ì‹¤ì œ ë°ì´í„°ë¥¼ ë„£ì–´ í•™ìŠµ ì‹œì‘       |

---

```python
model.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])
model.fit(train_scaled, train_target, epochs=5)
```

* kerasì—ì„œ ì„±ëŠ¥ í‰ê°€í•˜ëŠ” ë©”ì„œë“œ = evaluate()

# ì†ì‹¤í•¨ìˆ˜ ì •ë¦¬
ì¢‹ìŠµë‹ˆë‹¤! ì§€ê¸ˆê¹Œì§€ ë‹¤ë¤˜ë˜ ì†ì‹¤ í•¨ìˆ˜ ê´€ë ¨ ë‚´ìš©ì„ ëª¨ë‘ ì •ë¦¬í•˜ê³ , ì¶”ê°€ë¡œ \*\*`from_logits=True`\*\*ê¹Œì§€ í¬í•¨í•´ì„œ **ë”¥ëŸ¬ë‹ ì†ì‹¤ í•¨ìˆ˜ ì™„ì „ ì •ë¦¬íŒ**ì„ ë§Œë“¤ì–´ë“œë¦´ê²Œìš”.
ì²˜ìŒ ê³µë¶€í•˜ëŠ” ì‚¬ëŒë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í• ê²Œìš”.

---

# ğŸ“˜ ì†ì‹¤ í•¨ìˆ˜ (Loss Function) ì™„ì „ ì •ë¦¬

---

## âœ… 1. ì†ì‹¤ í•¨ìˆ˜ë€?

> **ì†ì‹¤ í•¨ìˆ˜ = ì˜ˆì¸¡ê°’ê³¼ ì •ë‹µ ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ìˆ˜ì¹˜ë¡œ ë‚˜íƒ€ë‚¸ í•¨ìˆ˜**

* í•™ìŠµí•  ë•Œ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ í‹€ë ¸ëŠ”ì§€ë¥¼ ìˆ˜ì¹˜í™”í•¨
* ì´ ì†ì‹¤ê°’ì„ ì¤„ì´ë„ë¡ \*\*ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •(ì—­ì „íŒŒ)\*\*í•¨

---

## âœ… 2. ë¶„ë¥˜ ë¬¸ì œì—ì„œ ë§ì´ ì“°ëŠ” ì†ì‹¤ í•¨ìˆ˜ 3ì¢…

| ì´ë¦„                                | ìš©ë„             | ì •ë‹µ í˜•ì‹         | ì¶œë ¥ì¸µ í™œì„±í™” |
| --------------------------------- | -------------- | ------------- | ------- |
| `binary_crossentropy`             | ì´ì§„ ë¶„ë¥˜ (0 ë˜ëŠ” 1) | ì •ìˆ˜(0/1) or í™•ë¥  | sigmoid |
| `categorical_crossentropy`        | ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜      | **ì›-í•« ë²¡í„°**    | softmax |
| `sparse_categorical_crossentropy` | ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜      | **ì •ìˆ˜ ë¼ë²¨**     | softmax |

---

## âœ… 3. `categorical_crossentropy` vs `sparse_categorical_crossentropy`

| í•­ëª©         | `categorical_crossentropy`  | `sparse_categorical_crossentropy` |
| ---------- | --------------------------- | --------------------------------- |
| ì •ë‹µ ë¼ë²¨ í˜•ì‹   | ì›-í•« ì¸ì½”ë”© `[0, 0, 1, 0, ...]` | ì •ìˆ˜ ì¸ë±ìŠ¤ `2`                        |
| ì›-í•« ì¸ì½”ë”© í•„ìš” | âœ… í•„ìš”                        | âŒ ë¶ˆí•„ìš”                             |
| ë‚´ë¶€ ì²˜ë¦¬ ë°©ì‹   | ì§ì ‘ ê³„ì‚°                       | ë‚´ë¶€ì ìœ¼ë¡œ ìë™ ì¸ì½”ë”© í›„ ê³„ì‚°                 |
| ì‚¬ìš© í¸ì˜ì„±     | ë¶ˆí¸ (ë³€í™˜ í•„ìš”)                  | í¸í•¨ (ì •ìˆ˜ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥)                 |

---

## âœ… 4. softmaxì™€ crossentropy ê´€ê³„

### ğŸ”¹ `softmax`

* ì¶œë ¥ì¸µì—ì„œ ì‚¬ìš©ë˜ëŠ” í•¨ìˆ˜
* ì…ë ¥ê°’(logits)ì„ í™•ë¥ ë¡œ ë³€í™˜
* ëª¨ë“  í´ë˜ìŠ¤ í™•ë¥  í•© = 1

### ğŸ”¹ `crossentropy`

* ì˜ˆì¸¡ í™•ë¥ ê³¼ ì •ë‹µ ê°„ì˜ ì°¨ì´ ê³„ì‚°
* ì •ë‹µ í´ë˜ìŠ¤ì˜ í™•ë¥ ì´ ë†’ì„ìˆ˜ë¡ ì†ì‹¤ ì‘ì•„ì§

---

## âœ… 5. `from_logits=True`ë€?

### ğŸ”¸ logitsë€?

> **logits = softmax ì „ì— ê³„ì‚°ëœ "ê°€ê³µë˜ì§€ ì•Šì€ ì¶œë ¥ê°’"**

ì˜ˆ: ëª¨ë¸ì´ ë§ˆì§€ë§‰ì— `Dense(10)`ë§Œ ìˆê³  softmaxê°€ ì—†ì„ ë•Œ
â†’ ì¶œë ¥ê°’ì€ \[2.3, -1.2, 0.7, ...] ê°™ì€ **ì›ì‹œ ì ìˆ˜**

### ğŸ”¸ ë¬¸ì œê°€ ë°œìƒí•˜ëŠ” ê²½ìš°

* `softmax`ê°€ ì—†ëŠ” ìƒíƒœì—ì„œ `categorical_crossentropy`ë¥¼ ê·¸ëƒ¥ ì“°ë©´
  â¤ **ìˆ«ìê°€ í™•ë¥ ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ì†ì‹¤ ê³„ì‚°ì´ ì˜ëª»ë¨**

### ğŸ”¸ í•´ê²° ë°©ë²•

> **ì†ì‹¤ í•¨ìˆ˜ì— `from_logits=True`ë¥¼ ì„¤ì •**í•˜ë©´, ë‚´ë¶€ì—ì„œ `softmax`ë¥¼ ìë™ìœ¼ë¡œ ì ìš©í•œ í›„ crossentropy ê³„ì‚°

---

### âœ… ì˜ˆì‹œ ì½”ë“œ ë¹„êµ

#### â‘  softmax í¬í•¨ â†’ `from_logits=False` (ê¸°ë³¸)

```python
model = keras.Sequential([
    keras.layers.Dense(10, activation='softmax')
])

model.compile(
    loss='sparse_categorical_crossentropy',  # from_logits=Falseê°€ ê¸°ë³¸
    optimizer='adam'
)
```

#### â‘¡ softmax ì—†ìŒ â†’ `from_logits=True`

```python
model = keras.Sequential([
    keras.layers.Dense(10)  # activation ì—†ìŒ = logits
])

loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)

model.compile(
    loss=loss_fn,
    optimizer='adam'
)
```

---

## âœ… 6. crossentropy ìˆ˜ì‹ ìš”ì•½

### One-hot ê¸°ì¤€ (categorical)

```
loss = -âˆ‘(y_true Ã— log(y_pred))
```

### ì •ìˆ˜ ê¸°ì¤€ (sparse)

```
loss = -log(y_pred[ì •ë‹µ ì¸ë±ìŠ¤])
```

### ì˜ˆì‹œ:

```python
ì˜ˆì¸¡ í™•ë¥ : [0.1, 0.2, 0.7]
ì •ë‹µ ì¸ë±ìŠ¤: 2

ì†ì‹¤ = -log(0.7)
```

---

## âœ… 7. ì´ì§„ ë¶„ë¥˜ì—ì„œ `binary_crossentropy`

* ì¶œë ¥ì¸µ: `Dense(1, activation='sigmoid')`
* ì •ë‹µ: `0` ë˜ëŠ” `1`
* ì†ì‹¤:

```
loss = -[y*log(p) + (1-y)*log(1-p)]
```

* ë§Œì•½ sigmoid ìƒëµ ì‹œ â†’ `from_logits=True` ì‚¬ìš©í•´ì•¼ í•¨

---

## âœ… 8. ì‹œê°ì  ë¹„êµ ìš”ì•½

| ëª¨ë¸ êµ¬ì¡°                           | ì†ì‹¤ í•¨ìˆ˜                                             | ì •ë‹µ ë¼ë²¨                | `from_logits` ì„¤ì • |
| ------------------------------- | ------------------------------------------------- | -------------------- | ---------------- |
| Dense(10, activation='softmax') | `sparse_categorical_crossentropy`                 | \[3, 2, 1, 0, ...]   | âŒ (ê¸°ë³¸ê°’)          |
| Dense(10) (ì†Œí”„íŠ¸ë§¥ìŠ¤ ì—†ìŒ)            | `SparseCategoricalCrossentropy(from_logits=True)` | \[3, 2, 1, ...]      | âœ… ê¼­ í•„ìš”           |
| Dense(10, activation='softmax') | `categorical_crossentropy`                        | \[\[0,0,1,...], ...] | âŒ (ê¸°ë³¸ê°’)          |
| Dense(1, activation='sigmoid')  | `binary_crossentropy`                             | \[0, 1, 0, 1]        | âŒ                |
| Dense(1)                        | `BinaryCrossentropy(from_logits=True)`            | \[0, 1, 0, 1]        | âœ…                |

---

